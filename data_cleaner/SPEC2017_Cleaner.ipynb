{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tYfI7JZxIzZS2vPQXOJfvqI8r9qby4k0",
      "authorship_tag": "ABX9TyP8NvsaboocoLt42OHDHTa6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cengizmehmet/BenchmarkNets/blob/main/data_cleaner/SPEC2017_Cleaner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREPROCESSING OF THE SPEC CPU2017 DATASET**"
      ],
      "metadata": {
        "id": "iBHHRGNRM6ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepared by Mehmet CENGIZ**\n",
        "\n",
        "ORCID: 0000-0003-4972-167X\n",
        "\n",
        "As we use this format of the SPEC2017 dataset in our studies, we modify the original dataset based on our requirements. Those who will use this script is free to modify this adhering to their needs."
      ],
      "metadata": {
        "id": "Yx86g1qwO1ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "riNhaheHO8GT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script is prepared for making operable the SPEC2017 dataset to use in our further studies. Even though the dataset was prepared carefully by practitioners, there are many unnecessary and untidy data in it. We will explain every process applied on columns onwards."
      ],
      "metadata": {
        "id": "eo0tmJA1v6Jj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NECESSARY DEPENDENCIES AND LIBRARIES**"
      ],
      "metadata": {
        "id": "kG3mYApAgWAo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdW_TVIWbfKb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from typing import Tuple\n",
        "import enum"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Versions:** This information is the library versions in Google Colab when the models were first designed (around the end of 2022). Version differences may occur due to time and programming environment changes.\n",
        "\n",
        "* Python: 3.8.16\n",
        "* Pandas: 1.3.5\n",
        "* Regular expression: 2.2.1"
      ],
      "metadata": {
        "id": "ccqw-7snw-oR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "X1uCYGM5OFzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'https://raw.githubusercontent.com/cengizmehmet/BenchmarkNets/main/data/SPEC2017_Original.csv'"
      ],
      "metadata": {
        "id": "MgmBV_Rlr3Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "Oq7LsHm5sF0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **THE DATASET BEFORE PREPROCESSING**"
      ],
      "metadata": {
        "id": "S2AyJ9orALWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After preprocessing, the dataset will be changed in many ways. In the section below, we present the original formats of some columns of the dataset."
      ],
      "metadata": {
        "id": "EsCAa0j9APyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Column names:**"
      ],
      "metadata": {
        "id": "pjZUHertoM8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset.columns))\n",
        "print(dataset.columns)"
      ],
      "metadata": {
        "id": "_3h3nAoG28Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data types:**"
      ],
      "metadata": {
        "id": "Ie4VVGHI7kM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.dtypes"
      ],
      "metadata": {
        "id": "DU8GOby_7n0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shape:**"
      ],
      "metadata": {
        "id": "7rPsSDlQ7uLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "-Rl1nXzv7wNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The dataset itself:**"
      ],
      "metadata": {
        "id": "WhkkvpKMoP0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab's dataset formatter is not working properly, because of so many columns and rows. The limit is 20 columns and 20000 rows. Those who want to see the dataset tidier and more interactive may click the baton symbol left down corner after running the following line."
      ],
      "metadata": {
        "id": "KSZB0lKZN5Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "0rgZRXdQNefp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Common Functions"
      ],
      "metadata": {
        "id": "Qt7whaYvSlK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some functions below require a column name as the parameter. In order to prevent errors from passing in invalid constants, we have defined an enumeration class."
      ],
      "metadata": {
        "id": "XLGGNbzrrlRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Column_Names(enum.Enum):\n",
        "  benchmark = \"Benchmark\"\n",
        "  vendor = \"Hardware_Vendor\"\n",
        "  system = \"System\"\n",
        "  cores = \"#_Cores\"\n",
        "  chips = \"#_Chips\"\n",
        "  threads = \"#_Enabled_Threads_Per_Core\"\n",
        "  processor = \"Processor\"\n",
        "  mhz = \"Processor_MHz\"\n",
        "  cpus = \"CPU(s)_Orderable\"\n",
        "  parallel = \"Parallel\"\n",
        "  base_pointer = \"Base_Pointer_Size\"\n",
        "  peak_pointer = \"Peak_Pointer_Size\"\n",
        "  first_cache = \"1st_Level_Cache\"\n",
        "  second_cache = \"2nd_Level_Cache\"\n",
        "  third_cache = \"3rd_Level_Cache\"\n",
        "  other_cache = \"Other_Cache\"\n",
        "  memory = \"Memory\"\n",
        "  storage = \"Storage\"\n",
        "  os = \"Operating_System\"\n",
        "  file_system = \"File_System\"\n",
        "  compiler = \"Compiler\"\n",
        "  hw = \"HW_Avail\"\n",
        "  sw = \"SW_Avail\"\n",
        "  license = \"License\"\n",
        "  tested_by = \"Tested_By\"\n",
        "  sponsor = \"Test_Sponsor\"\n",
        "  date = \"Test_Date\"\n",
        "  published = \"Published\"\n",
        "  updated = \"Updated\"\n",
        "  disclosure = \"Disclosures\"\n",
        "  result = \"Base_Result\"\n",
        "  energy = \"Energy_Base_Result\""
      ],
      "metadata": {
        "id": "_TXFKdwDDhli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** drop_empties\n",
        "\n",
        "**Parameters:** pd.DataFrame, Column_Names, str\n",
        "\n",
        "**Return:** pd.DataFrame\n",
        "\n",
        "This function deletes the rows containing the character entered according to the specified column. e.g. delete rows with value of 0 in the Result column."
      ],
      "metadata": {
        "id": "S97tUcfcsqIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_empties(dataset: pd.DataFrame, column_name: Column_Names, empty_character: str) -> pd.DataFrame:\n",
        "  dataset.drop(dataset.index[dataset[column_name.value] == empty_character], inplace = True)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "TQ3wcC3GDa6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** remove_between_with_delimiter\n",
        "\n",
        "**Parameters:** pd.DataFrame, str, str\n",
        "\n",
        "**Return:** pd.DataFrame\n",
        "\n",
        "This function removes all characters between two delimiters including delimiters from a string. e. g.\n",
        "> input: Test system (test info)\n",
        "\n",
        "> delimiters: \"(\" and \")\"\n",
        "\n",
        "> output: Test system"
      ],
      "metadata": {
        "id": "sZhr2MzU8a6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_between_with_delimiter(column: pd.DataFrame.columns, delimiter1: str, delimiter2: str) -> pd.DataFrame.columns:\n",
        "  column = list(column)\n",
        "  delimiter1 = \"\\\\\" + delimiter1\n",
        "  delimiter2 = \"\\\\\" + delimiter2\n",
        "  pattern = pattern = delimiter1 + \".*?\" + delimiter2\n",
        "  count = 0\n",
        "  while count < len(column):\n",
        "    column[count] = re.sub(pattern, \"\", column[count])\n",
        "    count += 1\n",
        "  column = [s.strip() for s in column]\n",
        "  return column"
      ],
      "metadata": {
        "id": "py9NtTy2ja6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** remove_after_with_delimiter\n",
        "\n",
        "**Parameters:** pd.DataFrame, str, str\n",
        "\n",
        "**Return:** pd.DataFrame\n",
        "\n",
        "This function removes all characters after a delimiter including the delimiter from a string. e. g.\n",
        "> input: \"Test system - test info\"\n",
        "\n",
        "> delimiter: \"-\"\n",
        "\n",
        "> output: \"Test system\""
      ],
      "metadata": {
        "id": "hZeaPAyh9eJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_after_with_delimiter(column: pd.DataFrame.columns, delimiter: str) -> pd.DataFrame.columns:\n",
        "  column = list(column)\n",
        "  count = 0\n",
        "  while count < len(column):\n",
        "    column[count] = column[count].split(delimiter, 1)[0]\n",
        "    count += 1\n",
        "  column = [s.strip() for s in column]\n",
        "  return column"
      ],
      "metadata": {
        "id": "Kzck6BymN2TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** eliminate_non_digits\n",
        "\n",
        "**Parameters:** str\n",
        "\n",
        "**Return:** int\n",
        "\n",
        "This function removes all non-digit characters from a string and returns an integer. e. g.\n",
        "> input: 45 kb info\n",
        "\n",
        "> output: 45"
      ],
      "metadata": {
        "id": "ij7RtsyW9-uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminate_non_digits(text: str) -> int:\n",
        "  numeric_filter = filter(str.isdigit, text)\n",
        "  digits = \"\".join(numeric_filter)\n",
        "  if digits == \"\":\n",
        "    return 0\n",
        "  else:\n",
        "    return int(digits)"
      ],
      "metadata": {
        "id": "xaPAoifkXErZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** find_anagrams\n",
        "\n",
        "**Parameters:** pd.DataFrame.columns\n",
        "\n",
        "**Return:** Tuple[list, list]\n",
        "\n",
        "This function was designed to find the whole combinations of a string. The main goal is to find duplicates in columns such as \"Pentium dual core e2140\" and \"Pentium dualcore e2140\". The main approach is to find anagrams."
      ],
      "metadata": {
        "id": "4ocRiyDE-h3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_anagrams(column: pd.DataFrame.columns) -> Tuple[list, list]:\n",
        "  values = list(set(column))\n",
        "  checked = [False for i in range(len(values))]\n",
        "  originals = []\n",
        "  anagrams = []\n",
        "  i = 0\n",
        "  while i < len(values):\n",
        "    if checked[i] == False:\n",
        "      checked[i] = True\n",
        "      str1 = sorted((values[i].replace(\"-\", \"\")).replace(\" \",\"\"))\n",
        "      j = i + 1\n",
        "      while j < len(values):\n",
        "        if checked[j] == False:\n",
        "          str2 = sorted((values[j].replace(\"-\", \"\")).replace(\" \",\"\"))\n",
        "          if str1 == str2:\n",
        "            checked[j] = True\n",
        "            originals.append(values[i])\n",
        "            anagrams.append(values[j])\n",
        "            values[j] == values[i]          \n",
        "        j += 1\n",
        "    i += 1\n",
        "  return originals, anagrams"
      ],
      "metadata": {
        "id": "xYs---dgs89x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PRE CLEARING**"
      ],
      "metadata": {
        "id": "HnKIr7tPDPOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clearing column names**"
      ],
      "metadata": {
        "id": "ncqd65GoDeRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Column names have white spaces between words. In order to reach them easily in the script, we add \"_\" between words and trim each other. By doing this, a naming convention has been created."
      ],
      "metadata": {
        "id": "h0wNaHLPHzVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_column_names(dataset):\n",
        "  column_names = dataset.columns\n",
        "  column_names = [s.strip() for s in column_names]\n",
        "  column_names = [s.replace(' ', '_') for s in column_names]\n",
        "  dataset.columns = column_names\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "RMtel_M60Jke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = clean_column_names(dataset)"
      ],
      "metadata": {
        "id": "CIC1D8LZgPY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "id": "AIXhYQj_2YS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VVsheKCoDiM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clearing rows**"
      ],
      "metadata": {
        "id": "pSx1S6bT7U0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains some inconclusive tests. Result values were entered as 0 in these tests by the practitioners. First, we started by eliminating these lines."
      ],
      "metadata": {
        "id": "QCfP56E27giG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "empty_char = 0\n",
        "dataset = drop_empties(dataset, Column_Names.result, empty_char)"
      ],
      "metadata": {
        "id": "WeV6Pwhi5XMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5lZxuehZDkMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **COLUMNS THAT DO NOT NEED TO BE CHANGE**"
      ],
      "metadata": {
        "id": "Jnljevvqw1Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The columns below can be used as they are because their contents are clear. To provide a standard, we turned the string ones into lower cases.\n",
        "\n",
        "*   Benchmark\n",
        "*   #_Cores\n",
        "*   #_Chips\n",
        "*   #_Enabled_Threads_Per_Core\n",
        "*   Processor\n",
        "*   Processor MHz\n",
        "*   Parallel\n",
        "*   Base_Pointer_Size\n",
        "*   Peak_Pointer_Size\n",
        "*   1st Level Cache\n",
        "*   Other Cache\n",
        "*   Operating System\n",
        "*   File System\n",
        "*   Compiler\n",
        "*   HW_Avail\n",
        "*   SW_Avail\n",
        "*   License\n",
        "*   Test Date\n",
        "*   Published\n",
        "*   Updated\n",
        "*   Disclosures"
      ],
      "metadata": {
        "id": "xbexxWInw7Tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.benchmark.value] = dataset[Column_Names.benchmark.value].str.lower()\n",
        "dataset[Column_Names.benchmark.value] = dataset[Column_Names.benchmark.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.processor.value] = dataset[Column_Names.processor.value].str.lower()\n",
        "dataset[Column_Names.processor.value] = dataset[Column_Names.processor.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.parallel.value] = dataset[Column_Names.parallel.value].str.lower()\n",
        "dataset[Column_Names.parallel.value] = dataset[Column_Names.parallel.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.base_pointer.value] = dataset[Column_Names.base_pointer.value].str.lower()\n",
        "dataset[Column_Names.base_pointer.value] = dataset[Column_Names.base_pointer.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.peak_pointer.value] = dataset[Column_Names.peak_pointer.value].str.lower()\n",
        "dataset[Column_Names.peak_pointer.value] = dataset[Column_Names.peak_pointer.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.first_cache.value] = dataset[Column_Names.first_cache.value].str.lower()\n",
        "dataset[Column_Names.first_cache.value] = dataset[Column_Names.first_cache.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.other_cache.value] = dataset[Column_Names.other_cache.value].str.lower()\n",
        "dataset[Column_Names.other_cache.value] = dataset[Column_Names.other_cache.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.os.value] = dataset[Column_Names.os.value].str.lower()\n",
        "dataset[Column_Names.os.value] = dataset[Column_Names.os.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.file_system.value] = dataset[Column_Names.file_system.value].str.lower()\n",
        "dataset[Column_Names.file_system.value] = dataset[Column_Names.file_system.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.compiler.value] = dataset[Column_Names.compiler.value].str.lower()\n",
        "dataset[Column_Names.compiler.value] = dataset[Column_Names.compiler.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.hw.value] = dataset[Column_Names.hw.value].str.lower()\n",
        "dataset[Column_Names.hw.value] = dataset[Column_Names.hw.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.sw.value] = dataset[Column_Names.sw.value].str.lower()\n",
        "dataset[Column_Names.sw.value] = dataset[Column_Names.sw.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.date.value] = dataset[Column_Names.date.value].str.lower()\n",
        "dataset[Column_Names.date.value] = dataset[Column_Names.date.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.published.value] = dataset[Column_Names.published.value].str.lower()\n",
        "dataset[Column_Names.published.value] = dataset[Column_Names.published.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.updated.value] = dataset[Column_Names.updated.value].str.lower()\n",
        "dataset[Column_Names.updated.value] = dataset[Column_Names.updated.value].str.strip()\n",
        "\n",
        "dataset[Column_Names.disclosure.value] = dataset[Column_Names.disclosure.value].str.lower()\n",
        "dataset[Column_Names.disclosure.value] = dataset[Column_Names.disclosure.value].str.strip()"
      ],
      "metadata": {
        "id": "z4XcezUIe4J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The columns \"Result\" and \"Baseline\" are the possible target attributes. Therefore we do not change them."
      ],
      "metadata": {
        "id": "jBF7NM-jyEXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **COLUMNS TO BE CORRECTED**"
      ],
      "metadata": {
        "id": "UhrIihzOzwV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **HARDWARE VENDOR**"
      ],
      "metadata": {
        "id": "aXjUtvbhkDyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Originally, there are 59 different hardware vendors. However, after we cleaned the rows containing 0 values, the number decreased to 53."
      ],
      "metadata": {
        "id": "wHxxSkH7uWWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.vendor.value] = dataset[Column_Names.vendor.value].str.lower()\n",
        "dataset[Column_Names.vendor.value] = dataset[Column_Names.vendor.value].str.strip()\n",
        "vendors = set(list(dataset[Column_Names.vendor.value]))\n",
        "print(len(vendors))\n",
        "print(sorted(vendors))"
      ],
      "metadata": {
        "id": "087kAM24vQ1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the column, there are duplicated vendors such as \"giga-byte technology co., ltd\" and \"giga-byte technology co., ltd.\" -the diffrence is the punctuation at the end. We need to make them one. It is a quite straightforward process, there is no smart approach. However, in order to not lose any vendor the coding order is important."
      ],
      "metadata": {
        "id": "x-sx1M-7vjOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"incorporated\")\n",
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"computing\")\n",
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"computer\")\n",
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"systems\")\n",
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"inc.\")\n",
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"sp.\")\n",
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"technology\")\n",
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"corporation\")\n",
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"enterprise\")\n",
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"global\")\n",
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"technologies\")\n",
        "dataset[Column_Names.vendor.value] = dataset[Column_Names.vendor.value].replace(\"new h3c\", \"h3c\")\n",
        "dataset[Column_Names.vendor.value] = remove_after_with_delimiter(dataset[Column_Names.vendor.value], \"cloud\")"
      ],
      "metadata": {
        "id": "8H0N-bR1IFA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three exceptions:\n",
        "\n",
        "\n",
        "1.   M Computers' name must be still as it is.\n",
        "2.   Sun Microsystems is also known as Sun. For further processes, we decided to use it as Sun.\n",
        "3.   AsusTek is also known as Asus."
      ],
      "metadata": {
        "id": "3PDMQdAKjgeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "hw_vendors = list(dataset[Column_Names.vendor.value])\n",
        "while i < len(dataset[Column_Names.vendor.value]):\n",
        "  if hw_vendors[i] == \"m\":\n",
        "    hw_vendors[i] = \"m computers\"\n",
        "  elif hw_vendors[i] == \"sun micro\":\n",
        "    hw_vendors[i] = \"sun\"\n",
        "  elif hw_vendors[i] == \"asustek\":\n",
        "    hw_vendors[i] = \"asus\"\n",
        "  i += 1\n",
        "dataset[Column_Names.vendor.value] = hw_vendors"
      ],
      "metadata": {
        "id": "9IRdd1wxjtg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a result, the number of vendors downs to 34. Duplicates and unnecessary parts were eliminated."
      ],
      "metadata": {
        "id": "WKw6EqC9wxPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vendors = set(list(dataset['Hardware_Vendor']))\n",
        "print(len(vendors))\n",
        "print(sorted(vendors))"
      ],
      "metadata": {
        "id": "Ryl3sqswkMvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ORDERABLE CPU(s)**"
      ],
      "metadata": {
        "id": "5YIs9wUZwHtW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Orderable_CPU(s)` column has duplicated values such as \"1,2 chips\" and \"1,2 chip(s)\". Also, it contains blank values."
      ],
      "metadata": {
        "id": "UUzmHTLVwqOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].str.lower()\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].str.strip()\n",
        "cpus = set(list(dataset[Column_Names.cpus.value].astype(str)))\n",
        "print(len(cpus))\n",
        "print(sorted(cpus))"
      ],
      "metadata": {
        "id": "ir7JOFUBQ3nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].str.replace(\" \", \"\")"
      ],
      "metadata": {
        "id": "r_JG88ocUQmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].str.replace(\",\", \"-\")"
      ],
      "metadata": {
        "id": "_stndrcEWRz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`1 chip`:"
      ],
      "metadata": {
        "id": "Gl6nAyxITMjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1chip\", \"1 chip\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1chip(s)\", \"1 chip\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1chips\", \"1 chip\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1cpuchip;2-3-4-..6cores\", \"1 chip\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1xhip\", \"1 chip\")"
      ],
      "metadata": {
        "id": "g6VAjUKpQ3dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`1-2` chips:"
      ],
      "metadata": {
        "id": "lWDlIJqdTOp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2chips\", \"1-2 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2\", \"1-2 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2(chip)s\", \"1-2 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2(chips)s\", \"1-2 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2chip\", \"1-2 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2chip(s)\", \"1-2 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1.2chips\", \"1-2 chips\")"
      ],
      "metadata": {
        "id": "_PVhus1JQ3X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`1-4 chips`:"
      ],
      "metadata": {
        "id": "KW0x5S5IZAr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2-3-4chip\", \"1-4 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2-3-4chip(s)\", \"1-4 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2-3-4chips\", \"1-4 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-4chips\", \"1-4 chips\")"
      ],
      "metadata": {
        "id": "IK5gj1B7ZCMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`1-8 chips`:"
      ],
      "metadata": {
        "id": "WgucHzAAYtus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2-3-4-5-6-7-8chips\", \"1-8 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-8chips\", \"1-8 chips\")"
      ],
      "metadata": {
        "id": "G0IdtkttYveq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`1-16 chips`, `1-16 cmious`, `1-24 chips`, and `1-32 chips`:"
      ],
      "metadata": {
        "id": "NU2k0GxAXJrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-16chips\", \"1-16 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-16cmiou(onhost)\", \"1-16 cmiou\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-24chips\", \"1-24 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-32chips\", \"1-32 chips\")"
      ],
      "metadata": {
        "id": "x5eCR3alXJDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`1,2,4 chips`:"
      ],
      "metadata": {
        "id": "9wl4wLb5ZkgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2-4(chip)s\", \"1,2,4 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2-4chip(s)\", \"1,2,4 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"1-2-4chips\", \"1,2,4 chips\")"
      ],
      "metadata": {
        "id": "aCL1GyqYZmoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`2 chips`:"
      ],
      "metadata": {
        "id": "Yw9MaQfodXcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2chip\", \"2 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2chips\", \"2 chips\")"
      ],
      "metadata": {
        "id": "acXVijoCdYxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`2-4 chips`:"
      ],
      "metadata": {
        "id": "vcEKNCP8bzZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2-3-4chips\", \"2-4 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2-4\", \"2-4 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2-4chips\", \"2-4 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2-4chip(s)\", \"2-4 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2-4chip\", \"2-4 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2or4chips\", \"2-4 chips\")"
      ],
      "metadata": {
        "id": "MMAa_JD7byqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`2-4-8 chips`, `2-4-6-8 chips`, `2-3-4-6-8 chips`, and `2-4-8-16 chips`:"
      ],
      "metadata": {
        "id": "Wcz9EfCmcjt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2-4-8chip(s)\", \"2-4-8 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2-4-8chips\", \"2-4-8 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2-4-6-8chips\", \"2-4-6-8 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2-3-4-6-8chips\", \"2-3-4-6-8 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2-4-8-16chip\", \"2-4-8-16 chips\")"
      ],
      "metadata": {
        "id": "455FlYkfcnkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`2-16 chips`:"
      ],
      "metadata": {
        "id": "2Tw1j0vldD25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"2to16chips\", \"2-16 chips\")"
      ],
      "metadata": {
        "id": "WzJs6d7zdFi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`3-4 chips`:"
      ],
      "metadata": {
        "id": "YRoxcZkopdTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"3-4chips\", \"3-4 chips\")"
      ],
      "metadata": {
        "id": "yZc3KvOLpfiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`4 chips`:"
      ],
      "metadata": {
        "id": "k4OUzxTFpn92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"4chips\", \"4 chips\")"
      ],
      "metadata": {
        "id": "1SYRfn4tppTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`4-8 chips`, `4-8-16 chips`, and `4-32 chips`:"
      ],
      "metadata": {
        "id": "6K8IsWLrpvIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"4-8chips\", \"4-8 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"4-8-16chips\", \"4-8-16 chips\")\n",
        "dataset[Column_Names.cpus.value] = dataset[Column_Names.cpus.value].replace(\"4to32chips\", \"4-32 chips\")"
      ],
      "metadata": {
        "id": "415-XFu5TMAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CACHES**"
      ],
      "metadata": {
        "id": "tsVSYI_suNCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the dataset, there are 4 types of caches: 1st Level, 2nd Level, 3rd Level, and Other. Except for the first level and other caches, they need to be corrected in different ways."
      ],
      "metadata": {
        "id": "nMbrBb0Iu8BF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2nd Level Cache**\n",
        "\n",
        "There are 7 different types of 2nd level caches. Only the \"2 mb i on chip per chip (256 kb / 4 cores); 4 mb d on chip per chip (256 kb / 2 cores)\" must be corrected."
      ],
      "metadata": {
        "id": "DTneu-hmCnAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.second_cache.value] = dataset[Column_Names.second_cache.value].str.lower()\n",
        "dataset[Column_Names.second_cache.value] = dataset[Column_Names.second_cache.value].str.strip()"
      ],
      "metadata": {
        "id": "ScOMSduXeNQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_level_caches = set(list(dataset[Column_Names.second_cache.value]))\n",
        "print(len(second_level_caches))\n",
        "print(second_level_caches)"
      ],
      "metadata": {
        "id": "BxnuJ2AruMkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.second_cache.value] = dataset[Column_Names.second_cache.value].replace(\n",
        "    \"2 mb i on chip per chip (256 kb / 4 cores); 4 mb d on chip per chip (256 kb / 2 cores)\",\n",
        "    \"2 mb i on chip per chip + 4 mb d on chip per chip\")"
      ],
      "metadata": {
        "id": "ofJj4G0n5KZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3rd Level Cache**\n",
        "\n",
        "There are 74 different types of 3rd level caches. We cleaned up some information that seems unnecessary. Fortunately, information such as that was mostly stored after the comma."
      ],
      "metadata": {
        "id": "37CwhD7tIsC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.third_cache.value] = dataset[Column_Names.third_cache.value].str.lower()\n",
        "dataset[Column_Names.third_cache.value] = dataset[Column_Names.third_cache.value].str.strip()"
      ],
      "metadata": {
        "id": "g-p4o5OIiwUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third_level_caches = set(list(dataset[Column_Names.third_cache.value]))\n",
        "print(len(third_level_caches))\n",
        "print(third_level_caches)"
      ],
      "metadata": {
        "id": "j8M4z9rGIsC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.third_cache.value] = remove_after_with_delimiter(dataset[Column_Names.third_cache.value], \",\")\n",
        "dataset[Column_Names.third_cache.value] = remove_after_with_delimiter(dataset[Column_Names.third_cache.value], \"shared\")\n",
        "dataset[Column_Names.third_cache.value] = remove_after_with_delimiter(dataset[Column_Names.third_cache.value], \"(\")"
      ],
      "metadata": {
        "id": "nu-VyGfyi0O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SYSTEM**"
      ],
      "metadata": {
        "id": "Nkyc8bT7gFBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In many cases, system names involve both the vendor's name and the processor specs. We have to get rid of them because that information has its own columns."
      ],
      "metadata": {
        "id": "8k_Fk6viD5ex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** remove_vendor_names\n",
        "\n",
        "**Parameters:** pd.DataFrame.columns, pd.DataFrame.columns\n",
        "\n",
        "**Return:** pd.DataFrame.columns\n",
        "\n",
        "This function deletes vendor names in system names."
      ],
      "metadata": {
        "id": "OWYwyzKrEy4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_vendor_names(systems: pd.DataFrame.columns, vendors: pd.DataFrame.columns) -> pd.DataFrame.columns:\n",
        "  vendors = list(set(list(vendors)))\n",
        "  systems = list(systems)\n",
        "  i = 0\n",
        "  while i < len(systems):\n",
        "    j = 0\n",
        "    temp = systems[i].strip()\n",
        "    while j < len(vendors):\n",
        "      if vendors[j] in temp:\n",
        "        start_index = systems[i].find(vendors[j])\n",
        "        end_index = start_index + len(vendors[j])\n",
        "        temp = temp[0:start_index:] + temp[end_index::]\n",
        "        systems[i] = temp.strip()\n",
        "        break\n",
        "      j +=1\n",
        "    i += 1\n",
        "  return systems"
      ],
      "metadata": {
        "id": "RF84_ShUBtVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.system.value] = dataset[Column_Names.system.value].str.lower()\n",
        "dataset[Column_Names.system.value] = dataset[Column_Names.system.value].str.strip()"
      ],
      "metadata": {
        "id": "ZhATASQYqOHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "systems = set(list(dataset[Column_Names.system.value]))"
      ],
      "metadata": {
        "id": "1n4j3lj5_TCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.system.value] = remove_after_with_delimiter(dataset[Column_Names.system.value], \"(\")\n",
        "dataset[Column_Names.system.value] = remove_after_with_delimiter(dataset[Column_Names.system.value], \",\")\n",
        "dataset['System'] = remove_vendor_names(dataset[Column_Names.system.value], dataset[Column_Names.vendor.value])\n",
        "dataset[Column_Names.system.value] = remove_after_with_delimiter(dataset[Column_Names.system.value], \"2.\")\n",
        "dataset[Column_Names.system.value] = remove_after_with_delimiter(dataset[Column_Names.system.value], \"3.\")\n",
        "dataset[Column_Names.system.value] = remove_after_with_delimiter(dataset[Column_Names.system.value], \"intel\")\n",
        "dataset[Column_Names.system.value] = remove_after_with_delimiter(dataset[Column_Names.system.value], \"amd\")"
      ],
      "metadata": {
        "id": "EErze1k0_EX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['System'] = dataset[Column_Names.system.value].str.strip()\n",
        "dataset = drop_empties(dataset, Column_Names.system, \"\")"
      ],
      "metadata": {
        "id": "FDBnyd-6_EVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After eliminating redundancy from the dataset, we have to manage typos. In some cases, some system names were entered with different ways such as \"yr190b8228\" and \"yr190 b8228\".\n",
        "\n",
        "To solve this problem, we designed a method that finds anagrams as mentioned earlier. However, this cannot help us totally. Because there are real anagrams in the dataset such as \"proliant ml350 gen 10\" and \"proliant ml350 gen10\". \n",
        "\n",
        "On the other hand, with the help of anagrams, we narrowed the search space down. The anagram finder finds 47 anagrams."
      ],
      "metadata": {
        "id": "UqF4Z-SKAuer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_systems, system_anagrams = find_anagrams(dataset['System'])"
      ],
      "metadata": {
        "id": "pe3pgbkHdXWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we eliminate duplicated and typoed entries manually selecting from the list below."
      ],
      "metadata": {
        "id": "w0p_1DCEC2UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "while i < len(system_anagrams):\n",
        "  print(original_systems[i] + \" - \" + system_anagrams[i])\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "x_Fn0T6dj_ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a result, we corrected 15 different system entries manually as below."
      ],
      "metadata": {
        "id": "BzJpdWzkGsnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.system.value] = dataset[Column_Names.system.value].replace(\"proliant ml350 gen 10\", \"proliant ml350 gen10\")\n",
        "dataset[Column_Names.system.value] = dataset[Column_Names.system.value].replace(\"8100v5\", \"8100 v5\")\n",
        "dataset[Column_Names.system.value] = dataset[Column_Names.system.value].replace(\"poweredge r750 xa\", \"poweredge r750xa\")\n",
        "dataset[Column_Names.system.value] = dataset[Column_Names.system.value].replace(\"prolaint dl385 gen10\", \"proliant dl385 gen10\")"
      ],
      "metadata": {
        "id": "50O5_hDlCjmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MEMORY**"
      ],
      "metadata": {
        "id": "kb6CvWATAmN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the dataset, the Memory column contains not only the size of the system memory but also the combination of memory components such as \"32 GB (4 x 8 GB 2Rx8 PC3-12800E-11, ECC)\". Also, because of TB to GB conversions, some of them indicate the same size. So we cleaned them up."
      ],
      "metadata": {
        "id": "xeEDLHbEAmN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.memory.value] = dataset[Column_Names.memory.value].str.lower()\n",
        "dataset[Column_Names.memory.value] = dataset[Column_Names.memory.value].str.strip()"
      ],
      "metadata": {
        "id": "FfphsaCSAmN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.memory.value] = remove_after_with_delimiter(dataset[Column_Names.memory.value], \"(\")\n",
        "dataset[Column_Names.memory.value] = dataset[Column_Names.memory.value].str.strip()"
      ],
      "metadata": {
        "id": "_2u2ja-2BvDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memories = set(list(dataset[Column_Names.memory.value]))"
      ],
      "metadata": {
        "id": "6uT9I5hDAsF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memories"
      ],
      "metadata": {
        "id": "AzOTs0zUAsDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After eliminating non-essential parts, from TB and GB to MB conversions is applied. As cache sizes, we use the thousand systems: 1 TB = 1000 GB and 1 GB = 1000 MB."
      ],
      "metadata": {
        "id": "QP4BWNrIV865"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column = list(dataset[Column_Names.memory.value])\n",
        "i = 0\n",
        "while i < len(column):\n",
        "  if \"gb\" in column[i]:\n",
        "    x = eliminate_non_digits(column[i])\n",
        "    column[i] = 1000 * eliminate_non_digits(column[i])\n",
        "  else:\n",
        "    x = eliminate_non_digits(column[i])\n",
        "    column[i] = 1000000 * eliminate_non_digits(column[i])\n",
        "  i += 1\n",
        "dataset[Column_Names.memory.value] = column"
      ],
      "metadata": {
        "id": "NmedMRgwwmn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STORAGE**"
      ],
      "metadata": {
        "id": "Vag1oXroe-tX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There 426 different types of storages in the dataset. As a result of the following actions, we left behind the dimensions of the storage areas rather than their specifications."
      ],
      "metadata": {
        "id": "kQVVfQfve-tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.storage.value] = dataset[Column_Names.storage.value].str.lower()\n",
        "dataset[Column_Names.storage.value] = dataset[Column_Names.storage.value].str.strip()"
      ],
      "metadata": {
        "id": "JRRkXN-3fWd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storage = set(list(dataset[Column_Names.storage.value]))"
      ],
      "metadata": {
        "id": "9EFI25yufWd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storage"
      ],
      "metadata": {
        "id": "KNBTgSuDXmie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.storage.value] = dataset[Column_Names.storage.value].str.replace(\" \", \"\")"
      ],
      "metadata": {
        "id": "SZS826bGQ3Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column = list(dataset[Column_Names.storage.value])\n",
        "i = 0\n",
        "plain_pattern = r'[0-9]*\\.?[0-9]+[gt]b'\n",
        "pattern_with_x = r'^[0-9]+x[0-9]+\\.?[0-9]*[gt]b'\n",
        "typo_pattern = r'[0-9]*\\.?[0-9]+[gt]'\n",
        "while i < len(column):\n",
        "  temp = re.findall(pattern_with_x, column[i])\n",
        "  if temp:\n",
        "    mult, data = temp[0].split(\"x\")\n",
        "    mult = float(mult)\n",
        "    modifier = data[len(data) - 2 : len(data)]\n",
        "    size = float(data[ : len(data) - 2])\n",
        "    column[i] = mult * size\n",
        "    if modifier == \"tb\":\n",
        "        column[i] *= 1000\n",
        "  else:\n",
        "    temp = re.findall(plain_pattern, column[i])\n",
        "    if temp:\n",
        "      temp = temp[0]\n",
        "      modifier = temp[len(temp) - 2 : len(temp)]\n",
        "      size = float(temp[ : len(temp) - 2])\n",
        "      column[i] = size\n",
        "      if modifier == \"tb\":\n",
        "        column[i] *= 1000\n",
        "    else:\n",
        "      temp = re.findall(typo_pattern, column[i])\n",
        "      if temp:\n",
        "        temp = temp[0]\n",
        "        modifier = temp[len(temp) - 1 : len(temp)]\n",
        "        size = float(temp[ : len(temp) - 1])\n",
        "        column[i] = size\n",
        "        if modifier == \"tb\":\n",
        "          column[i] *= 1000\n",
        "  i += 1\n",
        "dataset[Column_Names.storage.value] = column"
      ],
      "metadata": {
        "id": "6bJT_Xv-v0uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TESTED BY**"
      ],
      "metadata": {
        "id": "uSCeumfkq_Pd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tests in the dataset were applied by 36 different practitioners. However, like the `Hardware_Vendor` column, there are duplicated values."
      ],
      "metadata": {
        "id": "peN2cqraq_Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.tested_by.value] = dataset[Column_Names.tested_by.value].str.lower()\n",
        "dataset[Column_Names.tested_by.value] = dataset[Column_Names.tested_by.value].str.strip()"
      ],
      "metadata": {
        "id": "RX9sn58yDU8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tested_by = set(list(dataset[Column_Names.tested_by.value]))"
      ],
      "metadata": {
        "id": "jslQApIwrDpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tested_by"
      ],
      "metadata": {
        "id": "qfVQNsA1rDm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.tested_by.value] = remove_after_with_delimiter(dataset[Column_Names.tested_by.value], \"incorporated\")\n",
        "dataset[Column_Names.tested_by.value] = remove_after_with_delimiter(dataset[Column_Names.tested_by.value], \"computing\")\n",
        "dataset[Column_Names.tested_by.value] = remove_after_with_delimiter(dataset[Column_Names.tested_by.value], \"computer\")\n",
        "dataset[Column_Names.tested_by.value] = remove_after_with_delimiter(dataset[Column_Names.tested_by.value], \"systems\")\n",
        "dataset[Column_Names.tested_by.value] = remove_after_with_delimiter(dataset[Column_Names.tested_by.value], \"inc.\")\n",
        "dataset[Column_Names.tested_by.value] = remove_after_with_delimiter(dataset[Column_Names.tested_by.value], \"sp.\")\n",
        "dataset[Column_Names.tested_by.value] = remove_after_with_delimiter(dataset[Column_Names.tested_by.value], \"corporation\")\n",
        "dataset[Column_Names.tested_by.value] = remove_after_with_delimiter(dataset[Column_Names.tested_by.value], \"technologies\")\n",
        "dataset[Column_Names.tested_by.value] = dataset[Column_Names.tested_by.value].replace(\"new h3c\", \"h3c\")\n",
        "dataset[Column_Names.tested_by.value] = remove_after_with_delimiter(dataset[Column_Names.tested_by.value], \"global\")\n",
        "dataset[Column_Names.tested_by.value] = remove_after_with_delimiter(dataset[Column_Names.tested_by.value], \"co.\")"
      ],
      "metadata": {
        "id": "Sy7hJY8prDjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TEST SPONSOR**"
      ],
      "metadata": {
        "id": "VxZKULjNuhnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each test's sponsor is a different company/corporation. In total, there 36 different sponsors. However, like the `Hardware_Vendor` column, there are duplicated values."
      ],
      "metadata": {
        "id": "5mYt2OfsuhnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.sponsor.value] = dataset[Column_Names.sponsor.value].str.lower()\n",
        "dataset[Column_Names.sponsor.value] = dataset[Column_Names.sponsor.value].str.strip()"
      ],
      "metadata": {
        "id": "zOenCiFJuhnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sponsor = set(list(dataset[Column_Names.sponsor.value]))"
      ],
      "metadata": {
        "id": "elfeIiUjuhnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sponsor"
      ],
      "metadata": {
        "id": "sUGWcJSpuhnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[Column_Names.sponsor.value] = remove_after_with_delimiter(dataset[Column_Names.sponsor.value], \"incorporated\")\n",
        "dataset[Column_Names.sponsor.value] = remove_after_with_delimiter(dataset[Column_Names.sponsor.value], \"computing\")\n",
        "dataset[Column_Names.sponsor.value] = remove_after_with_delimiter(dataset[Column_Names.sponsor.value], \"computer\")\n",
        "dataset[Column_Names.sponsor.value] = remove_after_with_delimiter(dataset[Column_Names.sponsor.value], \"systems\")\n",
        "dataset[Column_Names.sponsor.value] = remove_after_with_delimiter(dataset[Column_Names.sponsor.value], \"inc.\")\n",
        "dataset[Column_Names.sponsor.value] = remove_after_with_delimiter(dataset[Column_Names.sponsor.value], \"sp.\")\n",
        "dataset[Column_Names.sponsor.value] = remove_after_with_delimiter(dataset[Column_Names.sponsor.value], \"corporation\")\n",
        "dataset[Column_Names.sponsor.value] = remove_after_with_delimiter(dataset[Column_Names.sponsor.value], \"technologies\")\n",
        "dataset[Column_Names.sponsor.value] = dataset[Column_Names.sponsor.value].replace(\"new h3c\", \"h3c\")\n",
        "dataset[Column_Names.sponsor.value] = remove_after_with_delimiter(dataset[Column_Names.sponsor.value], \"global\")\n",
        "dataset[Column_Names.sponsor.value] = remove_after_with_delimiter(dataset[Column_Names.sponsor.value], \"co.\")"
      ],
      "metadata": {
        "id": "DH2mD35urDd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EXPORTING THE DATASET**"
      ],
      "metadata": {
        "id": "Cq5nz88_df6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_excel(r'SPEC2017_modified.xlsx', index = False, header = True)"
      ],
      "metadata": {
        "id": "gUgpB4-WZ8wG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}